{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dan Waters - CSCE 5218 Final Project (Orchestration Example)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeUMWhpJ2obp2sFMQevf4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danwaters/lfi/blob/main/Dan_Waters_CSCE_5218_Final_Project_(Orchestration_Example).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB8pj4XolC5c"
      },
      "source": [
        "The purpose of this notebook is to demonstrate an end-to-end prediction involving both the image classifier and the appropriate text generator. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndZIW1ylk7WO",
        "outputId": "e2f29deb-8878-45d1-c701-d5e30470865a"
      },
      "source": [
        "!git clone https://github.com/danwaters/lfi.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'lfi' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzHqsz6MmqBa"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import preprocessing\n",
        "from keras import utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm9CN_EXpq5U"
      },
      "source": [
        "IMG_HEIGHT = 180\n",
        "IMG_WIDTH = 180"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiNpRyuwm1HG",
        "outputId": "8792bee9-a4d9-4bdd-af89-9038d9025fd9"
      },
      "source": [
        "classifier_model = keras.models.load_model(\"lfi/saved_models/classifier\", compile=False)\n",
        "\n",
        "test_url = \"https://www.rollingstone.com/wp-content/uploads/2018/06/rs-240736-GettyImages-91150536.jpg\"\n",
        "test_path = tf.keras.utils.get_file('dylan', origin=test_url)\n",
        "class_names = ['beatles', 'bob-dylan', 'michael-jackson', 'zappa']\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    test_path, target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = classifier_model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "class_name = class_names[np.argmax(score)]\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_name, 100 * np.max(score))\n",
        ")\n",
        "\n",
        "# call the appropriate language generation model\n",
        "nl_model = keras.models.load_model(f'lfi/saved_models/{artist}_lyrics', compile=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This image most likely belongs to bob-dylan with a 100.00 percent confidence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V5jdjb2sg2t"
      },
      "source": [
        "def generate_text(model, max_sequence_length, seed_text=\"she\", next_words=100, sequence_word_length=6):\n",
        "  \"\"\" This method generates next_words words based on the seed text by\n",
        "  repeatedly feeding the last sequence_length words into the LSTM to make the\n",
        "  prediction. It keeps track of every word generated and prints the result.\"\"\"\n",
        "  t = Tokenizer()\n",
        "  text = open('lfi/train/bob-dylan.txt', 'rb').read().decode(encoding='utf-8')\n",
        "  sentences = text.lower().replace(\"\\r\\n\", \"\\n\").split(\"\\n\")\n",
        "  # fit the tokenizer\n",
        "  t.fit_on_texts(sentences)\n",
        "\n",
        "  # Seed and run predictions\n",
        "  total_text = seed_text\n",
        "\n",
        "  for i in range(next_words):\n",
        "    token_list = t.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], \n",
        "                               maxlen=max_sequence_length - 1,\n",
        "                               padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    output_word = \"\"\n",
        "    for word, index in t.word_index.items():\n",
        "      if index == predicted:\n",
        "        output_word = word\n",
        "        break\n",
        "    total_text += \" \" + output_word\n",
        "    seed_text = seed_text + \" \" + output_word\n",
        " \n",
        "    # if seed_text is n words or more, drop the first word in the sequence.\n",
        "    seed_words = seed_text.split(' ')\n",
        "    if len(seed_words) >= sequence_word_length:\n",
        "      seed_text = ' '.join(seed_words[1:])\n",
        "\n",
        "  out = \"\"\n",
        "  for i, w in enumerate(total_text.split(' ')):\n",
        "    out = out + \" \" + w\n",
        "    if i % sequence_word_length == 0 and i > 0: # insert line breaks every 5 words\n",
        "      out += \"\\r\\n\"\n",
        "  \n",
        "  return out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylf3sQiZo_ri",
        "outputId": "33fac61e-f87f-431d-a1e3-f79658d7a0b4"
      },
      "source": [
        "out = generate_text(nl_model, 32)\n",
        "print(out)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " she by heart by you down he\r\n",
            " you what was complete my the\r\n",
            " table back want the trust did\r\n",
            " bleachers they oh mistreat i we\r\n",
            " mixed it’s the cravin’ proved it\r\n",
            " that would time the quit leaves\r\n",
            " it’s back behind hangin’ near and\r\n",
            " this she out many fade know\r\n",
            " ain’t sold know the explain nails\r\n",
            " needs on oh  i’ll i\r\n",
            " wiggle plan walkin' anymore the need\r\n",
            " spark see disillusioned they you just\r\n",
            " you dance me clarkesdale they you\r\n",
            " a terrible narrow ’bove in the\r\n",
            " enough   longin’ i if\r\n",
            " want worked is broken and i'm\r\n",
            " off the happened my\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dszc8r2lsp89"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}